{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data and Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, bring in all the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import regex as re\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of future warnings would otherwise pop up in this notebook, so I am essentially turning them off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in the populated science and comedy data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "science = pd.read_csv('./data/sciencedata.csv')\n",
    "comedy = pd.read_csv('./data/comedydata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the two dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([science, comedy], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2868, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fentanyl Surpasses Heroin As Drug Most Often I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Seattle, Washington, delaying the start tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>College textbooks aimed at introductory biolog...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scary warming at poles showing up at weird tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>An invasive species of tick - the first of its...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  science\n",
       "0  Fentanyl Surpasses Heroin As Drug Most Often I...        1\n",
       "1  In Seattle, Washington, delaying the start tim...        1\n",
       "2  College textbooks aimed at introductory biolog...        1\n",
       "3  Scary warming at poles showing up at weird tim...        1\n",
       "4  An invasive species of tick - the first of its...        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.shape)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a function to clean up all the posts at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean the data in posts column\n",
    "def post_to_words(post):\n",
    "    #grab the text from each post\n",
    "    post_text = BeautifulSoup(post).get_text()\n",
    "    \n",
    "    #use regex to keep the letters and get rid of punctuation\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", post_text)\n",
    "    \n",
    "    #make all the words lowercase\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    #gather all the stop words (most common words like \"a\", \"and\", etc\n",
    "    stops = set(stopwords.words('english'))\n",
    "    \n",
    "    #keep only the non stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fentanyl surpasses heroin drug often involved ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seattle washington delaying start time two hig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>college textbooks aimed introductory biology c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scary warming poles showing weird times places...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>invasive species tick first kind emerge us yea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  science\n",
       "0  fentanyl surpasses heroin drug often involved ...        1\n",
       "1  seattle washington delaying start time two hig...        1\n",
       "2  college textbooks aimed introductory biology c...        1\n",
       "3  scary warming poles showing weird times places...        1\n",
       "4  invasive species tick first kind emerge us yea...        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run the above function on all posts in the df\n",
    "data.posts = data.posts.apply(post_to_words)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish a baseline accuracy\n",
    "\n",
    "If the model just guessed nothing but non science posts, it would be just a little over 53% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.531381\n",
       "1    0.468619\n",
       "Name: science, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.science.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign feature and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.posts\n",
    "y = data.science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "#stratify to make sure both sets have a similar breakdown of 1 and 0 labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()        #instantiate count vectorizer to turn our posts into features for the model\n",
    "log = LogisticRegression()    #instantiate logsitic regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline for more efficient hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline to help gridsearch parameters for\n",
    "#count vectorizer and logistic regression\n",
    "pipe = Pipeline([  \n",
    "    ('cv', cv),\n",
    "    ('log', log)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'cv__max_features': [4000, 5000, 6000],\n",
    "    'cv__max_df': [.1, .2, .3],\n",
    "    'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "    'log__penalty': ['l1', 'l2'],\n",
    "    'log__C': [2, 3, 4],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv = 3)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.1,\n",
       " 'cv__max_features': 5000,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'log__C': 3,\n",
       " 'log__penalty': 'l2'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the best parameters\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set optimal parameters for the vectorizer and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.1, max_features=5000)\n",
    "log = LogisticRegression(C=3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the array of word features and put them back into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                            columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                           columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model and get a column of predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = log.fit(X_train_vect, y_train)\n",
    "predictions = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the model on the test data.  This was my highest scoring model.  97.6% accuracy and the other metrics from the confusion matrix are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762900976290098"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     science       0.96      0.99      0.98       381\n",
      " not_science       0.99      0.96      0.97       336\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       717\n",
      "   macro avg       0.98      0.98      0.98       717\n",
      "weighted avg       0.98      0.98      0.98       717\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, predictions,\n",
    "                               target_names=['science', 'not_science'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 378\n",
      "False Positives: 3\n",
      "False Negatives: 14\n",
      "True Positives: 322\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Tf-Idf vectorizer with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi = TfidfVectorizer()\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfi', tfi),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfi__max_features': [4000, 5000, 6000],\n",
    "    'tfi__max_df': [.1, .2, .3],\n",
    "    'rf__max_depth': [170, 180, 190],\n",
    "    'rf__min_samples_split': [4, 5, 6],\n",
    "    'rf__n_estimators': [80, 100]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=3)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf__max_depth': 170,\n",
       " 'rf__min_samples_split': 4,\n",
       " 'rf__n_estimators': 100,\n",
       " 'tfi__max_df': 0.2,\n",
       " 'tfi__max_features': 6000}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=6000, max_df=.2)\n",
    "rf = RandomForestClassifier(max_depth=180, min_samples_split=3,\n",
    "                            n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                            columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                          columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting and making predictions with the model.  This scored just slightly behind LogReg at 96.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rf.fit(X_train_vect, y_train)\n",
    "predictions = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9693165969316597"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 378\n",
      "False Positives: 3\n",
      "False Negatives: 19\n",
      "True Positives: 317\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi = TfidfVectorizer()\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfi', tfi),\n",
    "    ('mnb', mnb)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfi__max_features': [7000, 8000, 9000],\n",
    "    'tfi__ngram_range':[(1, 1), (1, 2), (1, 3)],\n",
    "    'tfi__max_df': [.05, .1, .2],\n",
    "    'tfi__norm': ['l1', 'l2', None],\n",
    "    'tfi__binary': [False, True],\n",
    "    'mnb__alpha': [0.1, 0.2, 0.3]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid=params, cv=5)\n",
    "gs.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mnb__alpha': 0.3,\n",
       " 'tfi__binary': True,\n",
       " 'tfi__max_df': 0.1,\n",
       " 'tfi__max_features': 8000,\n",
       " 'tfi__ngram_range': (1, 2),\n",
       " 'tfi__norm': 'l2'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out MultiNomial Naive Bayes, Bagging Classifier, and Ada Boost as well\n",
    "- Repeat the hyperparameter tuning, fitting, and scoring processes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=8000, binary=True, max_df=.1,\n",
    "                      ngram_range=(1,2), norm='l2')\n",
    "\n",
    "mnb = MultinomialNB(alpha=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                           columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                          columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mnb.fit(X_train_vect, y_train)\n",
    "predict = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9651324965132496"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 378\n",
      "False Positives: 3\n",
      "False Negatives: 19\n",
      "True Positives: 317\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "bag = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('bag', bag)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cv__max_features': [750, 1000],\n",
    "    'cv__max_df': [.4, .5, .6],\n",
    "    'cv__ngram_range': [(1,1), (1, 2), (1, 3)],\n",
    "    'bag__n_estimators': [125, 150]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__n_estimators': 125,\n",
       " 'cv__max_df': 0.5,\n",
       " 'cv__max_features': 1000,\n",
       " 'cv__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_df=.4, max_features=1000)\n",
    "bag = BaggingClassifier(n_estimators=125, base_estimator=DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                           columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                          columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = bag.fit(X_train_vect, y_train)\n",
    "predictions = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9595536959553695"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', cv),\n",
    "    ('ada', ada)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'cv__max_features': [1500, 2000, 3000, 4000],\n",
    "    'cv__max_df': [.4, .5, .6],\n",
    "    'ada__n_estimators': [150, 200, 250]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__n_estimators': 250, 'cv__max_df': 0.6, 'cv__max_features': 2000}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=2000, max_df=.6)\n",
    "ada = AdaBoostClassifier(n_estimators=250, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                            columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                           columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ada.fit(X_train_vect, y_train)\n",
    "predictions = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada Boost gave me my second highest accuracy score, but I ended up including Logistic Regression and Random Forest as my two models to display.  I chose Random Forest because it takes slightly less time to run and Logistic Regression because it score highest and is a little easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9735006973500697"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfi = TfidfVectorizer()\n",
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfi', tfi),\n",
    "    ('ada', ada)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'tfi__max_features': [3000, 4000, 5000],\n",
    "    'tfi__max_df': [.3, .4, .5],\n",
    "    'ada__n_estimators': [250, 300]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, param_grid=params)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__n_estimators': 250, 'tfi__max_df': 0.3, 'tfi__max_features': 4000}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=4000, max_df=.3)\n",
    "ada = AdaBoostClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect = pd.DataFrame(vect.fit_transform(X_train).todense(),\n",
    "                           columns=vect.get_feature_names())\n",
    "\n",
    "X_test_vect = pd.DataFrame(vect.transform(X_test).todense(),\n",
    "                          columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ada.fit(X_train_vect, y_train)\n",
    "predictions = model.predict(X_test_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9456066945606695"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_vect, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 364\n",
      "False Positives: 17\n",
      "False Negatives: 22\n",
      "True Positives: 314\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
