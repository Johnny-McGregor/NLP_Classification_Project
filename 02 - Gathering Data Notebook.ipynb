{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data from Reddit API\n",
    "Starting with required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking out the details of the JSON file, acquired by adding the .json extension to the end of subreddit url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.reddit.com/r/science/.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create my own unique header so that I do not get a status error\n",
    "headers = {'User-agent': 'Jingle Bells 2.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#200 means we are good to go. #400 means its a problem on the user's end\n",
    "#500 means there is a problem on reddit's end\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn the output of the requests.get into a json format \n",
    "the_json = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'kind']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the keys of the json\n",
    "sorted(the_json.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['after', 'before', 'children', 'dist', 'modhash']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out the nested keys within 'data'\n",
    "sorted(the_json['data'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin with an empty lists for the posts and an empty dictionary for the parameters.  Run the for loop once to get the first 100 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "after = None\n",
    "for i in range(4):\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after': after}\n",
    "    #start with the science posts\n",
    "    url = 'https://www.reddit.com/r/science/.json'\n",
    "    res = requests.get(url, params = params, headers = headers)\n",
    "    if res.status_code == 200:\n",
    "        the_json = res.json()\n",
    "        posts.extend(the_json['data']['children'])\n",
    "        after = the_json['data']['after']\n",
    "    \n",
    "    #in case there is a status error we will break the for loop and see\n",
    "    #what kind of error it is\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(1)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure there are posts in the list\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the list has begun populating, run this for loop so that it doesn't write over what is already in the list.  I can run this cell multiple times to continue gathering posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    if after == None:\n",
    "        params = {}\n",
    "    else:\n",
    "        params = {'after': after}\n",
    "    url = 'https://www.reddit.com/r/science/.json'\n",
    "    res = requests.get(url, params=params, headers = headers)\n",
    "    if res.status_code == 200:\n",
    "        the_json = res.json()\n",
    "        posts.extend(the_json['data']['children'])\n",
    "        after = the_json['data']['after']\n",
    "    else:\n",
    "        print(res.status_code)\n",
    "        break\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two lines of code will show how many total posts are in the list and how many unique (non duplicated) posts there are.  Once the first line does not match the second line, we know we've gotten all the unique posts we can for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(posts))\n",
    "display(len(set([p['data']['name'] for p in posts])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe with the populated posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all of the posts into a list\n",
    "title_lst = [p['data']['title'] for p in posts]\n",
    "#create a dictionary to eventually make into a dataframe\n",
    "data_dict = {\n",
    "    'posts':title_lst,\n",
    "    #this labels all the posts as a 1 for science.\n",
    "    #all the comedy posts will have a zero under the science column\n",
    "    'science': np.full(len(title_lst), 1)\n",
    "}\n",
    "\n",
    "post_df = pd.DataFrame.from_dict(data_dict, orient='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all of the duplicated posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure each post in the dataframe is unique\n",
    "unique_post_df = post_df[~post_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posts</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analysing data about cannabis use among more t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breeding bees with \"clean genes\" could help pr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New research suggests that megaliths — monumen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eleven spiders from the Cretaceous period have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Teachers’ helping behaviors leads to better st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               posts  science\n",
       "0  Analysing data about cannabis use among more t...        1\n",
       "1  Breeding bees with \"clean genes\" could help pr...        1\n",
       "2  New research suggests that megaliths — monumen...        1\n",
       "3  Eleven spiders from the Cretaceous period have...        1\n",
       "4  Teachers’ helping behaviors leads to better st...        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_post_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the science data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_post_df.to_csv('./datasets/unique_sciencedata', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the process for comedy posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
